% This document should contain your references in a format compatible with the natbib package.

@inproceedings{govindarajan-etal-2023-counterfactual,
    title = "Counterfactual Probing for the Influence of Affect and Specificity on Intergroup Bias",
    author = "Govindarajan, Venkata S  and
      Beaver, David  and
      Mahowald, Kyle  and
      Li, Junyi Jessy",
    author+an = {1=highlight},
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
        pages = "12853--12862",
    abstract = "While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts {---} thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models fine-tuned for predicting IGR reliably use affect in classification, the model{'}s usage of specificity is inconclusive.",
    keywords={resume}
}

@inproceedings{govindarajan-etal-2023-people,
    title = "How people talk about each other: Modeling Generalized Intergroup Bias and Emotion",
    author = "Govindarajan, Venkata S  and
      Atwell, Katherine  and
      Sinno, Barea  and
      Alikhani, Malihe  and
      Beaver, David  and
      Li, Junyi Jessy",
    author+an = {1=highlight},
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
        pages = "2488--2498",
    abstract = "Current studies of bias in NLP rely mainly on identifying (unwanted or negative) bias towards a specific demographic group. While this has led to progress recognizing and mitigating negative bias, and having a clear notion of the targeted group is necessary, it is not always practical. In this work we extrapolate to a broader notion of bias, rooted in social science and psychology literature. We move towards predicting interpersonal group relationship (IGR) - modeling the relationship between the speaker and the target in an utterance - using fine-grained interpersonal emotions as an anchor. We build and release a dataset of English tweets by US Congress members annotated for interpersonal emotion - the first of its kind, and {`}found supervision{'} for IGR labels; our analyses show that subtle emotional signals are indicative of different biases. While humans can perform better than chance at identifying IGR given an utterance, we show that neural models perform much better; furthermore, a shared encoding between IGR and interpersonal perceived emotion enabled performance gains in both tasks.",
    keywords={resume}
}

@inproceedings{zad-etal-2021-hell,
    title = {{Hell Hath No Fury? Correcting Bias in the {NRC} Emotion Lexicon}},
    author = "Zad, Samira  and
      Jimenez, Joshuan  and
      Finlayson, Mark",
    booktitle = {{Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)}},
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "102--113",
    abstract = "There have been several attempts to create an accurate and thorough emotion lexicon in English, which identifies the emotional content of words. Of the several commonly used resources, the NRC emotion lexicon (Mohammad and Turney, 2013b) has received the most attention due to its availability, size, and its choice of Plutchik{'}s expressive 8-class emotion model. In this paper we identify a large number of troubling entries in the NRC lexicon, where words that should in most contexts be emotionally neutral, with no affect (e.g., {`}lesbian{'}, {`}stone{'}, {`}mountain{'}), are associated with emotional labels that are inaccurate, nonsensical, pejorative, or, at best, highly contingent and context-dependent (e.g., {`}lesbian{'} labeled as Disgust and Sadness, {`}stone{'} as Anger, or {`}mountain{'} as Anticipation). We describe a procedure for semi-automatically correcting these problems in the NRC, which includes disambiguating POS categories and aligning NRC entries with other emotion lexicons to infer the accuracy of labels. We demonstrate via an experimental benchmark that the quality of the resources is thus improved. We release the revised resource and our code to enable other researchers to reproduce and build upon results.",
}

@article{Mohammad2013CROWDSOURCINGAW,
  title={{Crowdsourcing a Word-Emotion Association Lexicon}},
  author={Saif M. Mohammad and Peter D. Turney},
  journal={Computational Intelligence},
  year={2013},
  volume={29},
  }

@inproceedings{mohammad-etal-2016-semeval,
    title = {{{S}em{E}val-2016 Task 6: Detecting Stance in Tweets}},
    author = "Mohammad, Saif  and
      Kiritchenko, Svetlana  and
      Sobhani, Parinaz  and
      Zhu, Xiaodan  and
      Cherry, Colin",
    booktitle = {{Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)}},
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
            pages = "31--41",
}


@article{beaver2018toward,
  title={{Toward a Non-Ideal Philosophy of Language}},
  author={Beaver, David and Stanley, Jason},
  journal={Graduate Faculty Philosophy Journal},
  volume={39},
  number={2},
  pages={503--547},
  year={2018},
  }

@article{Anolli2006LinguisticIB,
    title = {{Linguistic Intergroup Bias in Political Communication}},
        abstract = {The Linguistic Intergroup Bias ({LIB}) illustrates the disposition to communicate positive in-group and negative out-group behaviors more abstractly than negative ingroup and positive out-group behaviors. The present research examined the function of language in reinforcing this bias in political communication. To illustrate the {LIB}, the Linguistic Category Model ({LCM}) was used, including a nouns category. Because social stereotypes are usually conveyed by nominal terms, the aim was to observe the relationship between stereotypes and language in political communication. Moreover, we were interested in analyzing the psychological processes that drive the {LIB}. Therefore, we verified whether the {LIB} is more related to language abstractness than to agent-patient causality. Several political debates and interviews, which took place before the latest Italian provincial elections, were analyzed. Results suggested that the language politicians use in communicating about political groups are conceptualized as stereotypes rather than as trait-based categories. Moreover, it seems that the {LIB} could not be explained only at a lexical level. Social implications of the present findings in interpersonal relations and causal attribution were discussed.},
    journal={The Journal of General Psychology},
    author = {Luigi Anolli and Valentino Zurloni and Giuseppe Riva},
    year={2006},
    volume={133},
    pages={237 - 255}
}

@inproceedings{sheng-etal-2019-woman,
    title = {{The Woman Worked as a Babysitter: On Biases in Language Generation}},
    author = "Sheng, Emily  and
      Chang, Kai-Wei  and
      Natarajan, Premkumar  and
      Peng, Nanyun",
    booktitle = {{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}},
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
            pages = "3407--3412",
    abstract = "We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.",
}


@incollection{maass_linguistic_1999,
    title = {{Linguistic Intergroup Bias: Stereotype Perpetuation Through Language}},
    volume = {31},
        shorttitle = {{Linguistic Intergroup Bias}},
    abstract = {Language is considered as the major means by which stereotypes are communicated through interpersonal discourse, by which they are transmitted from generation to generation, and by which the press and other mass media create social representations of social groups. Language also constitutes the principal means by which sociologists and social-psychologists tend to measure stereotypes. Language abstraction plays a subtle but important role in stereotype transmission and maintenance. The aim of this chapter is to describe language abstraction and its development over the past years. The chapter discusses its implications and proposes extensions of the model to related areas. The linguistic intergroup bias ({LIB}) model describes a systematic bias in language use, which can contribute to the perpetuation of stereotypes. The chapter describes the research paradigm most frequently employed in {LIB} studies, reviews empirical findings testing the main predictions, addresses questions of external validity, compares hypotheses about the underlying mechanisms of the {LIB}, speculate about extensions of the model beyond intergroup relations, and finally discusses a number of open problems that are of interest.},
    pages = {79--121},
    booktitle = {{Advances in Experimental Social Psychology}},
    publisher = {Academic Press},
    author = {Maass, Anne},
    editor = {Zanna, Mark P.},
    urldate = {2020-10-11},
    date = {1999-01-01},
    year={1999},
    langid = {english},
}

@book{van2009society,
  title={{Society and Discourse: How Social Contexts Influence Text and Talk}},
  author={Van Dijk, Teun A},
  year={2009},
  publisher={Cambridge University Press},
  }

@inproceedings{mohammad-2012-emotional,
    title = {{{\#}Emotional Tweets}},
    author = "Mohammad, Saif",
    booktitle = {{*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)}},
    month = "7-8 " # jun,
    year = "2012",
    address = "Montr{\'e}al, Canada",
    publisher = "Association for Computational Linguistics",
        pages = "246--255",
}

@INPROCEEDINGS{6406313,  author={Wang, Wenbo and Chen, Lu and Thirunarayan, Krishnaprasad and Sheth, Amit P.},  booktitle={2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing},   title={{Harnessing Twitter "Big Data" for Automatic Emotion Identification}},   year={2012},  volume={},  number={},  pages={587-592},  }

@inproceedings{abdul-mageed-ungar-2017-emonet,
    title = {{{E}mo{N}et: {F}ine-{G}rained {E}motion {D}etection with {G}ated {R}ecurrent {N}eural {N}etworks}},
    author = "Abdul-Mageed, Muhammad  and
      Ungar, Lyle",
    booktitle = {{Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}},
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
            pages = "718--728",
    abstract = "Accurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding individuals and their lives. However, progress on emotion detection has been hampered by the absence of large labeled datasets. In this work, we build a very large dataset for fine-grained emotions and develop deep learning models on it. We achieve a new state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58{\%}). We also extend the task beyond emotion types to model Robert Plutick{'}s 8 primary emotion dimensions, acquiring a superior accuracy of 95.68{\%}.",
}


@article{hippel_linguistic_1997,
    title = {{The Linguistic Intergroup Bias As an Implicit Indicator of Prejudice}},
    volume = {33},
    pages = {490--509},
    journal = {Journal of Experimental Social Psychology},
    author = {Hippel, W. and Sekaquaptewa, Denise and Vargas, P.},
    date = {1997},
    year={1997},
    }

@article{plutchik2001nature,
  title={{The Nature of Emotions}},
  author={Plutchik, Robert},
  journal={American Scientist},
  volume={89},
  number={4},
  pages={344--350},
  year={2001},
    publisher={JSTOR}
}

@inproceedings{barbieri-etal-2020-tweeteval,
    title = {{{T}weet{E}val: Unified Benchmark and Comparative Evaluation for Tweet Classification}},
    author = "Barbieri, Francesco  and
      Camacho-Collados, Jose  and
      Espinosa Anke, Luis  and
      Neves, Leonardo",
    booktitle = {{Findings of the Association for Computational Linguistics: EMNLP 2020}},
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "1644--1650",
    abstract = "The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domain-specific data. In this paper, we propose a new evaluation framework (TweetEval) consisting of seven heterogeneous Twitter-specific classification tasks. We also provide a strong set of baselines as starting point, and compare different language modeling pre-training strategies. Our initial experiments show the effectiveness of starting off with existing pre-trained generic language models, and continue training them on Twitter corpora.",
}

@inproceedings{wang-manning-2012-baselines,
    title = {{Baselines and Bigrams: Simple, Good Sentiment and Topic Classification}},
    author = "Wang, Sida  and
      Manning, Christopher",
    booktitle = {{Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}},
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
        pages = "90--94",
}

@inproceedings{wolf-etal-2020-transformers,
    title = {{Transformers: State-of-the-Art Natural Language Processing}},
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = {{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}},
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
        pages = "38--45"
}

@article{Mohammad2015UsingHT,
  title={{Using Hashtags to Capture Fine Emotion Categories from Tweets}},
  author={Saif M. Mohammad and Svetlana Kiritchenko},
  journal={Computational Intelligence},
  year={2015},
  volume={31},
  pages={301 - 326},
  }

@article{Pryzant_DiehlMartinez_Dass_Kurohashi_Jurafsky_Yang_2020, title={{Automatically Neutralizing Subjective Bias in Text}}, volume={34},  abstractNote={&lt;p&gt;Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the form of inappropriate subjectivity — introducing attitudes via framing, presupposing truth, and casting doubt — remains ubiquitous. This kind of bias erodes our collective trust and fuels social conflict. To address this issue, we introduce a novel testbed for natural language generation: automatically bringing inappropriately subjective text into a neutral point of view (“neutralizing” biased text). We also offer the first parallel corpus of biased language. The corpus contains 180,000 sentence pairs and originates from Wikipedia edits that removed various framings, presuppositions, and attitudes from biased sentences. Last, we propose two strong encoder-decoder baselines for the task. A straightforward yet opaque concurrent system uses a BERT encoder to identify subjective words as part of the generation process. An interpretable and controllable modular algorithm separates these steps, using (1) a BERT-based classifier to identify problematic words and (2) a novel &lt;em&gt;join embedding&lt;/em&gt; through which the classifier can edit the hidden states of the encoder. Large-scale human evaluation across four domains (encyclopedias, news headlines, books, and political speeches) suggests that these algorithms are a first step towards the automatic identification and reduction of bias.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Pryzant, Reid and Diehl Martinez, Richard and Dass, Nathan and Kurohashi, Sadao and Jurafsky, Dan and Yang, Diyi}, year={2020}, month={Apr.}, pages={480-489} }

@inproceedings{sheng-etal-2020-towards,
    title = {{Towards {C}ontrollable {B}iases in {L}anguage {G}eneration}},
    author = "Sheng, Emily  and
      Chang, Kai-Wei  and
      Natarajan, Prem  and
      Peng, Nanyun",
    booktitle = {{Findings of the Association for Computational Linguistics: EMNLP 2020}},
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "3239--3254",
    abstract = "We present a general approach towards controllable societal biases in natural language generation (NLG). Building upon the idea of adversarial triggers, we develop a method to induce societal biases in generated text when input prompts contain mentions of specific demographic groups. We then analyze two scenarios: 1) inducing negative biases for one demographic and positive biases for another demographic, and 2) equalizing biases between demographics. The former scenario enables us to detect the types of biases present in the model. Specifically, we show the effectiveness of our approach at facilitating bias analysis by finding topics that correspond to demographic inequalities in generated text and comparing the relative effectiveness of inducing biases for different demographics. The second scenario is useful for mitigating biases in downstream applications such as dialogue generation. In our experiments, the mitigation technique proves to be effective at equalizing the amount of biases across demographics while simultaneously generating less negatively biased text overall.",
}

@inproceedings{webson-etal-2020-undocumented,
    title = {{Are {``}Undocumented Workers{''} the Same as {``}Illegal Aliens{''}? {D}isentangling Denotation and Connotation in Vector Spaces}},
    author = "Webson, Albert  and
      Chen, Zhizhong  and
      Eickhoff, Carsten  and
      Pavlick, Ellie",
    booktitle = {{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}},
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "4090--4105",
    abstract = "In politics, neologisms are frequently invented for partisan objectives. For example, {``}undocumented workers{''} and {``}illegal aliens{''} refer to the same group of people (i.e., they have the same denotation), but they carry clearly different connotations. Examples like these have traditionally posed a challenge to reference-based semantic theories and led to increasing acceptance of alternative theories (e.g., Two-Factor Semantics) among philosophers and cognitive scientists. In NLP, however, popular pretrained models encode both denotation and connotation as one entangled representation. In this study, we propose an adversarial nerual netowrk that decomposes a pretrained representation as independent denotation and connotation representations. For intrinsic interpretability, we show that words with the same denotation but different connotations (e.g., {``}immigrants{''} vs. {``}aliens{''}, {``}estate tax{''} vs. {``}death tax{''}) move closer to each other in denotation space while moving further apart in connotation space. For extrinsic application, we train an information retrieval system with our disentangled representations and show that the denotation vectors improve the viewpoint diversity of document rankings.",
}


@inproceedings{kaneko-bollegala-2019-gender,
    title = {{Gender-preserving Debiasing for Pre-trained Word Embeddings}},
    author = "Kaneko, Masahiro  and
      Bollegala, Danushka",
    booktitle = {{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}},
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
            pages = "1641--1650",
    abstract = "Word embeddings learnt from massive text collections have demonstrated significant levels of discriminative biases such as gender, racial or ethnic biases, which in turn bias the down-stream NLP applications that use those word embeddings. Taking gender-bias as a working example, we propose a debiasing method that preserves non-discriminative gender-related information, while removing stereotypical discriminative gender biases from pre-trained word embeddings. Specifically, we consider four types of information: \textit{feminine}, \textit{masculine}, \textit{gender-neutral} and \textit{stereotypical}, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.",
}


@inproceedings{nguyen_bertweet_2020,
    location = {Online},
    title = {{{BERTweet}: A pre-trained language model for English Tweets}},
            abstract = {We present {BERTweet}, the first public large-scale pre-trained language model for English Tweets. Our {BERTweet}, having the same architecture as {BERT}-base (Devlin et al., 2019), is trained using the {RoBERTa} pre-training procedure (Liu et al., 2019). Experiments show that {BERTweet} outperforms strong baselines {RoBERTa}-base and {XLM}-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet {NLP} tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release {BERTweet} under the {MIT} License to facilitate future research and applications on Tweet data. Our {BERTweet} is available at https://github.com/{VinAIResearch}/{BERTweet}},
    pages = {9--14},
    booktitle = {{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}},
    publisher = {Association for Computational Linguistics},
    author = {Nguyen, Dat Quoc and Vu, Thanh and Tuan Nguyen, Anh},
    date = {2020-10},
    year = {2020}
}

@inproceedings{aharoni-goldberg-2020-unsupervised,
    title = {{Unsupervised Domain Clusters in Pretrained Language Models}},
    author = "Aharoni, Roee  and
      Goldberg, Yoav",
    booktitle = {{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}},
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "7747--7763",
    abstract = "The notion of {``}in-domain data{''} in NLP is often over-simplistic and vague, as textual data varies in many nuanced linguistic aspects such as topic, style or level of formality. In addition, domain labels are many times unavailable, making it challenging to build domain-specific systems. We show that massive pre-trained language models implicitly learn sentence representations that cluster by domains without supervision {--} suggesting a simple data-driven definition of domains in textual data. We harness this property and propose domain data selection methods based on such models, which require only a small set of in-domain monolingual data. We evaluate our data selection methods for neural machine translation across five diverse domains, where they outperform an established approach as measured by both BLEU and precision and recall with respect to an oracle selection.",
}

@article{sainburg2021parametric,
  title={{Parametric UMAP Embeddings for Representation and Semisupervised Learning}},
  author={Sainburg, Tim and McInnes, Leland and Gentner, Timothy Q},
  journal={Neural Computation},
  volume={33},
  number={11},
  pages={2881--2907},
  year={2021},
  publisher={MIT Press},
}

@inproceedings{blodgett-etal-2020-language,
    title = {{Language (Technology) is Power: A Critical Survey of {``}Bias{''} in {NLP}}},
    author = "Blodgett, Su Lin  and
      Barocas, Solon  and
      Daum{\'e} III, Hal  and
      Wallach, Hanna",
    booktitle = {{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}},
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "5454--5476",
    abstract = "We survey 146 papers analyzing {``}bias{''} in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing {``}bias{''} is an inherently normative process. We further find that these papers{'} proposed quantitative techniques for measuring or mitigating {``}bias{''} are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing {``}bias{''} in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of {``}bias{''}---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements{---}and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",
}

@inproceedings{demszky-etal-2020-goemotions,
    title = {{{G}o{E}motions: A Dataset of Fine-Grained Emotions}},
    author = "Demszky, Dorottya  and
      Movshovitz-Attias, Dana  and
      Ko, Jeongwoo  and
      Cowen, Alan  and
      Nemade, Gaurav  and
      Ravi, Sujith",
    booktitle = {{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}},
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "4040--4054",
    abstract = "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement.",
}

@inproceedings{desai-etal-2020-detecting,
    title = {{Detecting Perceived Emotions in Hurricane Disasters}},
    author = "Desai, Shrey  and
      Caragea, Cornelia  and
      Li, Junyi Jessy",
    booktitle = {{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}},
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "5290--5305",
    abstract = "Natural disasters (e.g., hurricanes) affect millions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., Twitter) to share their sentiments and feelings with the larger community. Consequently, these platforms have become instrumental in understanding and perceiving emotions at scale. In this paper, we introduce HurricaneEmo, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarse-grained emotion groups. Our best BERT model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68{\%} accuracy (averaged across all groups). HurricaneEmo serves not only as a challenging benchmark for models but also as a valuable resource for analyzing emotions in disaster-centric domains.",
}

@inproceedings{merullo-etal-2019-investigating,
    title = "Investigating Sports Commentator Bias within a Large Corpus of {A}merican Football Broadcasts",
    author = "Merullo, Jack  and
      Yeh, Luke  and
      Handler, Abram  and
      Grissom II, Alvin  and
      O{'}Connor, Brendan  and
      Iyyer, Mohit",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
            pages = "6355--6361",
    abstract = "Sports broadcasters inject drama into play-by-play commentary by building team and player narratives through subjective analyses and anecdotes. Prior studies based on small datasets and manual coding show that such theatrics evince commentator bias in sports broadcasts. To examine this phenomenon, we assemble FOOTBALL, which contains 1,455 broadcast transcripts from American football games across six decades that are automatically annotated with 250K player mentions and linked with racial metadata. We identify major confounding factors for researchers examining racial bias in FOOTBALL, and perform a computational analysis that supports conclusions from prior social science studies.",
}

@inproceedings{liang-etal-2009-learning,
    title = "Learning Semantic Correspondences with Less Supervision",
    author = "Liang, Percy  and
      Jordan, Michael  and
      Klein, Dan",
    editor = "Su, Keh-Yih  and
      Su, Jian  and
      Wiebe, Janyce  and
      Li, Haizhou",
    booktitle = "Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP}",
    month = aug,
    year = "2009",
    address = "Suntec, Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "91--99",
}


@article{iyengar_origins_2019,
    title = {The Origins and Consequences of Affective Polarization in the United States},
    volume = {22},
            abstract = {While previously polarization was primarily seen only in issue-based terms, a new type of division has emerged in the mass public in recent years: Ordinary Americans increasingly dislike and distrust those from the other party. Democrats and Republicans both say that the other party's members are hypocritical, selfish, and closed-minded, and they are unwilling to socialize across party lines. This phenomenon of animosity between the parties is known as affective polarization. We trace its origins to the power of partisanship as a social identity, and explain the factors that intensify partisan animus. We also explore the consequences of affective polarization, highlighting how partisan affect influences attitudes and behaviors well outside the political sphere. Finally, we discuss strategies that might mitigate partisan discord and conclude with suggestions for future work.},
    pages = {129--146},
    number = {1},
    journaltitle = {Annual Review of Political Science},
    author = {Iyengar, Shanto and Lelkes, Yphtach and Levendusky, Matthew and Malhotra, Neil and Westwood, Sean J.},
    date = {2019},
}

@misc{horowitz2017nflscrapr,
  title={nflscrapR: Compiling the NFL play-by-play API for easy use in R},
  author={Horowitz, Maksim and Yurko, Ron and Ventura, S},
  url={https://github.com/maksimhorowitz/nflscrapR},
  year={2017}
}

@article{Yurko2018nflWARAR,
  title={nflWAR: a reproducible method for offensive player evaluation in football},
  author={Ronald Yurko and Samuel L. Ventura and Maksim Horowitz},
  journal={Journal of Quantitative Analysis in Sports},
  year={2018},
  volume={15},
  pages={163 - 183},
}

@misc{baldwin2021nflfastr,
  author = {Baldwin, Ben},
  title = {Open Source Football: nflfastR EP, WP, CP xYAC, and xPass models},
    year = {2021}
}


@article{pelechrinis2016anatomy,
  title={The anatomy of American football: evidence from 7 years of NFL game data},
  author={Pelechrinis, Konstantinos and Papalexakis, Evangelos},
  journal={PLoS one},
  volume={11},
  number={12},
  pages={e0168716},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{heineman2023thresh,
    title = "Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation",
    author = "Heineman, David  and
      Dou, Yao  and
      Xu, Wei",
    editor = "Feng, Yansong  and
      Lefever, Els",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "336--345",
    abstract = "Fine-grained, span-level human evaluation has emerged as a reliable and robust method for evaluating text generation tasks such as summarization, simplification, machine translation and news generation, and the derived annotations have been useful for training automatic metrics and improving language models. However, existing annotation tools implemented for these evaluation frameworks lack the adaptability to be extended to different domains or languages, or modify annotation settings according to user needs; and, the absence of a unified annotated data format inhibits the research in multi-task learning. In this paper, we introduce Thresh, a unified, customizable and deployable platform for fine-grained evaluation. With a single YAML configuration file, users can build and test an annotation interface for any framework within minutes {--} all in one web browser window. To facilitate collaboration and sharing, Thresh provides a community hub that hosts a collection of fine-grained frameworks and corresponding annotations made and collected by the community, covering a wide range of NLP tasks. For deployment, Thresh offers multiple options for any scale of annotation projects from small manual inspections to large crowdsourcing ones. Additionally, we introduce a Python library to streamline the entire process from typology design and deployment to annotation processing. Thresh is publicly accessible at https://thresh.tools.",
}


@InCollection{sep-mereology,
    author       =	{Varzi, Achille},
    title        =	{{Mereology}},
    booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
    editor       =	{Edward N. Zalta},
    year         =	{2019},
    edition      =	{{S}pring 2019},
    publisher    =	{Metaphysics Research Lab, Stanford University}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165},
}

@article{Chung2022ScalingIL,
  title={Scaling Instruction-fine-tuned Language Models},
  author={Hyung Won Chung and Le Hou and S. Longpre and Barret Zoph and Yi Tay and William Fedus and Eric Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Wei Yu and Vincent Zhao and Yanping Huang and Andrew M. Dai and Hongkun Yu and Slav Petrov and Ed Huai-hsin Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.11416},
}

@inproceedings{NEURIPS2022_9d560961,
 author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and ichter, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {24824--24837},
 publisher = {Curran Associates, Inc.},
 title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
 volume = {35},
 year = {2022}
}

@article{Wadhwa2023RevisitingRE,
  title={Revisiting Relation Extraction in the era of Large Language Models},
  author={Somin Wadhwa and Silvio Amir and Byron C. Wallace},
  journal={Proceedings of the conference. Association for Computational Linguistics. Meeting},
  year={2023},
  volume={2023},
  pages={
          15566-15589
        },
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@InProceedings{napoles-EtAl:2015:ACL-IJCNLP,
  author    = {Napoles, Courtney  and  Sakaguchi, Keisuke  and  Post, Matt  and  Tetreault, Joel},
  title     = {Ground Truth for Grammatical Error Correction Metrics},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = {July},
  year      = {2015},
  address   = {Beijing, China},
  publisher = {Association for Computational Linguistics},
  pages     = {588--593},
}

@inproceedings{woodard1982,
author = {Woodard, J.P. and Nelson, J.T.},
year = {1982},
journal = {Workshop on standardisation for speech I/O technology, Naval Air Development Center, Warminster, PA},
title = {An information theoretic measure of speech recognition performance}
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot et al.},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{geminiteam2023gemini,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team},
      year={2023},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Groeneveld2023OLMo,
  title={OLMo: Accelerating the Science of Language Models},
  author={Groeneveld, Dirk and Beltagy, Iz and Walsh, Pete and Bhagia, Akshita and Kinney, Rodney and Tafjord, Oyvind and Jha, Ananya Harsh and Ivison, Hamish and Magnusson, Ian and Wang, Yizhong and Arora, Shane and Atkinson, David and Authur, Russell and Chandu, Khyathi and Cohan, Arman and Dumas, Jennifer and Elazar, Yanai and Gu, Yuling and Hessel, Jack and Khot, Tushar and Merrill, William and Morrison, Jacob and Muennighoff, Niklas and Naik, Aakanksha and Nam, Crystal and Peters, Matthew E. and Pyatkin, Valentina and Ravichander, Abhilasha and Schwenk, Dustin and Shah, Saurabh and Smith, Will and Subramani, Nishant and Wortsman, Mitchell and Dasigi, Pradeep and Lambert, Nathan and Richardson, Kyle and Dodge, Jesse and Lo, Kyle and Soldaini, Luca and Smith, Noah A. and Hajishirzi, Hannaneh},
  journal={Preprint},
  year={2024}
}

@article{
srivastava2023beyond,
title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao et al.},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
note={}
}

@article{krishnamurthy2013jointly,
  title={Jointly learning to parse and perceive: Connecting natural language to the physical world},
  author={Krishnamurthy, Jayant and Kollar, Thomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={1},
  pages={193--206},
  year={2013},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA}
}

@article{Rashkin2015ConnotationFA,
  title={Connotation Frames: A Data-Driven Investigation},
  author={Hannah Rashkin and Sameer Singh and Yejin Choi},
  journal={arXiv: Computation and Language},
  year={2015}
}

@inproceedings{Sap2017ConnotationFO,
  title={Connotation Frames of Power and Agency in Modern Films},
  author={Maarten Sap and Marcella Cindy Prasettio and Ari Holtzman and Hannah Rashkin and Yejin Choi},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2017}
}

@article{gao_predicting_2019,
    title = {Predicting and Analyzing Language Specificity in Social Media Posts},
    volume = {33},
    rights = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
    issn = {2374-3468},
            abstract = {In computational linguistics, specificity quantifies how much detail is engaged in text. It is an important characteristic of speaker intention and language style, and is useful in {NLP} applications such as summarization and argumentation mining. Yet to date, expert-annotated data for sentence-level specificity are scarce and confined to the news genre. In addition, systems that predict sentence specificity are classifiers trained to produce binary labels (general or specific).We collect a dataset of over 7,000 tweets annotated with specificity on a fine-grained scale. Using this dataset, we train a supervised regression model that accurately estimates specificity in social media posts, reaching a mean absolute error of 0.3578 (for ratings on a scale of 1-5) and 0.73 Pearson correlation, significantly improving over baselines and previous sentence specificity prediction systems. We also present the first large-scale study revealing the social, temporal and mental health factors underlying language specificity on social media.},
    pages = {6415--6422},
    number = {1},
    journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
    author = {Gao, Yifan and Zhong, Yang and Preoţiuc-Pietro, Daniel and Li, Junyi Jessy},
    urldate = {2020-10-20},
    date = {2019-07-17},
    year={2019},
    langid = {english},
    note = {Number: 01}
}

@article{annurev2002,
author = {Hewstone, Miles and Rubin, Mark and Willis, Hazel},
title = {Intergroup Bias},
journal = {Annual Review of Psychology},
volume = {53},
number = {1},
pages = {575-604},
year = {2002},
    abstract = {This chapter reviews the extensive literature on bias in favor of in-groups at the expense of out-groups. We focus on five issues and identify areas for future research: (a) measurement and conceptual issues (especially in-group favoritism vs. out-group derogation, and explicit vs. implicit measures of bias); (b) modern theories of bias highlighting motivational explanations (social identity, optimal distinctiveness, uncertainty reduction, social dominance, terror management); (c) key moderators of bias, especially those that exacerbate bias (identification, group size, status and power, threat, positive-negative asymmetry, personality and individual differences); (d) reduction of bias (individual vs. intergroup approaches, especially models of social categorization); and (e) the link between intergroup bias and more corrosive forms of social hostility. }
}




@inproceedings{sap-etal-2020-social,
    title = "Social Bias Frames: Reasoning about Social and Power Implications of Language",
    author = "Sap, Maarten  and
      Gabriel, Saadia  and
      Qin, Lianhui  and
      Jurafsky, Dan  and
      Smith, Noah A.  and
      Choi, Yejin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "5477--5490",
    abstract = "Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people{'}s judgments about others. For example, given a statement that {``}we shouldn{'}t lower our standards to hire more women,{''} most listeners will infer the implicature intended by the speaker - that {``}women (candidates) are less qualified.{''} Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80{\%} F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.",
}

@inproceedings{gonen-goldberg-2019-lipstick,
    title = "Lipstick on a Pig: {D}ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them",
    author = "Gonen, Hila  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
            pages = "609--614",
    abstract = "Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between {``}gender-neutralized{''} words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.",
}

@inproceedings{agarwal-etal-2019-word,
    title = "Word Embeddings (Also) Encode Human Personality Stereotypes",
    author = "Agarwal, Oshin  and
      Durup{\i}nar, Funda  and
      Badler, Norman I.  and
      Nenkova, Ani",
    booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
            pages = "205--211",
    abstract = "Word representations trained on text reproduce human implicit bias related to gender, race and age. Methods have been developed to remove such bias. Here, we present results that show that human stereotypes exist even for much more nuanced judgments such as personality, for a variety of person identities beyond the typically legally protected attributes and that these are similarly captured in word representations. Specifically, we collected human judgments about a person{'}s Big Five personality traits formed solely from information about the occupation, nationality or a common noun description of a hypothetical person. Analysis of the data reveals a large number of statistically significant stereotypes in people. We then demonstrate the bias captured in lexical representations is statistically significantly correlated with the documented human bias. Our results, showing bias for a large set of person descriptors for such nuanced traits put in doubt the feasibility of broadly and fairly applying debiasing methods and call for the development of new methods for auditing language technology systems and resources.",
}


@incollection{beukeboom_mechanisms_2014,
    location = {New York, {NY}, {US}},
    title = {Mechanisms of linguistic bias: How words reflect and maintain stereotypic expectancies},
    isbn = {978-1-84872-664-2 978-1-84872-663-5 978-0-203-74462-8},
        series = {Sydney symposium of social psychology},
    shorttitle = {Mechanisms of linguistic bias},
    abstract = {Stereotypes about people are widespread and play a crucial role in social perception and interaction. An important question is how stereotypic expectancies about social categories are transmitted and maintained interpersonally. Although stereotypes and prejudice may be shared explicitly, most people disapprove of the explicit expression of stereotypes and especially racism, and it appears that stereotypes are predominantly shared at a largely implicit level. Research on linguistic bias has revealed a number of subtle systematic variations in language use that not only reflect stereotypic expectancies, but may also strengthen them in both sender and recipients. Research on this topic, however, has predominantly—and rather narrowly—focused on one linguistic aspect (i.e., language abstraction), where knowledge on other linguistic biases is scarce and scattered in the literature. This chapter reviews and aims to integrate the knowledge on the role of linguistic bias in stereotyping. It first reviews existing evidence for linguistic biases and the effects they have on recipients, the sender, and the collective. Subsequently, it discusses potential underlying mechanisms that these biases (may) have in common and explores future areas of research. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
    pages = {313--330},
    booktitle = {Social cognition and communication},
    publisher = {Psychology Press},
    author = {Beukeboom, Camiel J.},
    date = {2014},
    keywords = {Linguistics, Prejudice, Social Perception}
}



@inproceedings{rashid-blanco-2017-dimensions,
    title = "Dimensions of Interpersonal Relationships: Corpus and Experiments",
    author = "Rashid, Farzana  and
      Blanco, Eduardo",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
            pages = "2307--2316",
    abstract = "This paper presents a corpus and experiments to determine dimensions of interpersonal relationships. We define a set of dimensions heavily inspired by work in social science. We create a corpus by retrieving pairs of people, and then annotating dimensions for their relationships. A corpus analysis shows that dimensions can be annotated reliably. Experimental results show that given a pair of people, values to dimensions can be assigned automatically.",
}

@inproceedings{berg-kirkpatrick-etal-2012-empirical,
    title = "An Empirical Investigation of Statistical Significance in {NLP}",
    author = "Berg-Kirkpatrick, Taylor  and
      Burkett, David  and
      Klein, Dan",
    booktitle = "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
        pages = "995--1005",
}


@article{david2010,
author = { Jeffrey T.   Hancock  and  David I.   Beaver  and  Cindy K.   Chung  and  Joey   Frazee  and  James W.   Pennebaker  and  Art   Graesser  and  Zhiqiang   Cai },
title = {Social language processing: A framework for analyzing the communication of terrorists and authoritarian regimes},
journal = {Behavioral Sciences of Terrorism and Political Aggression},
volume = {2},
number = {2},
pages = {108-132},
year  = {2010},
publisher = {Routledge},

}


@article{greenwald_implicit_2006,
    title = {Implicit Bias: Scientific Foundations},
    volume = {94},
    issn = {0008-1221},
            shorttitle = {Implicit Bias},
    pages = {945--967},
    number = {4},
    journaltitle = {California Law Review},
    author = {Greenwald, Anthony G. and Krieger, Linda Hamilton},
    urldate = {2020-10-20},
    date = {2006},
    note = {Publisher: California Law Review, Inc.}
}


@article{maass_language_1989,
    title = {Language use in intergroup contexts: the linguistic intergroup bias.},
    volume = {57 6},
    pages = {981--93},
    journal = {Journal of personality and social psychology},
    author = {Maass, Anne and Salvi, Daniel Anthony and Arcuri, Luciano and Semin, Gün R.},
    date = {1989},
    year = {1989}}

@article{schnake_modern_1998,
    title = {Modern Racism as a predictor of the Linguistic Intergroup Bias},
    volume = {17},
        pages = {484--491},
    number = {4},
    journal = {Journal of Language and Social Psychology},
    author = {Schnake, Sherry B and Ruscher, Janet B},
    date = {1998},
    year={1998},
    Publisher = {{S}age {P}ublications, {I}nc. 2455 Teller Road, Thousand Oaks, {CA} 91320}
}


@article{semin_cognitive_1988,
    title = {The Cognitive functions of Linguistic Categories in describing persons: Social Cognition and Language},
    volume = {54},
    issn = {0022-3514},
            shorttitle = {The cognitive functions of linguistic categories in describing persons},
    pages = {558--568},
    journaltitle = {Journal of Personality and Social Psychology},
    shortjournal = {J Pers Soc Psychol},
    author = {Semin, G. R. and Fiedler, K.},
    urldate = {2020-10-20},
    year = {1988},
    note = {Publisher: American Psychological Association}
}

@inproceedings{ravfogel-etal-2021-counterfactual,
    title = "Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction",
    author = "Ravfogel, Shauli  and
      Prasad, Grusha  and
      Linzen, Tal  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "194--209",
}

@inproceedings{ravfogel-etal-2020-null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "7237--7256",
}

@inproceedings{gonen-etal-2020-greek,
    title = "It{'}s not {G}reek to m{BERT}: Inducing Word-Level Translations from Multilingual {BERT}",
    author = "Gonen, Hila  and
      Ravfogel, Shauli  and
      Elazar, Yanai  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
            pages = "45--56",
    abstract = "Recent works have demonstrated that multilingual BERT (mBERT) learns rich cross-lingual representations, that allow for transfer across languages. We study the word-level translation information embedded in mBERT and present two simple methods that expose remarkable translation capabilities with no fine-tuning. The results suggest that most of this information is encoded in a non-linear way, while some of it can also be recovered with purely linear tools. As part of our analysis, we test the hypothesis that mBERT learns representations which contain both a language-encoding component and an abstract, cross-lingual component, and explicitly identify an empirical language-identity subspace within mBERT representations.",
}

@inproceedings{li_fast_2015,
    title = {Fast and Accurate Prediction of Sentence Specificity},
    booktitle = {{AAAI}},
    author = {Li, Junyi Jessy and Nenkova, Ani},
    date = {2015},
}

@phdthesis{li_discourse_2017,
    title = {From Discourse Structure To Text Specificity: Studies Of Coherence Preferences},
    school = {University of Pennsylvania},
    type = {phdthesis},
    author = {Li, Junyi Jessy},
    year = {2017},
}

@inproceedings{louis-nenkova-2011-text,
    title = "Text Specificity and Impact on Quality of News Summaries",
    author = "Louis, Annie  and
      Nenkova, Ani",
    booktitle = "Proceedings of the Workshop on Monolingual Text-To-Text Generation",
    month = jun,
    year = "2011",
    address = "Portland, Oregon",
    publisher = "Association for Computational Linguistics",
        pages = "34--42",
}

@article{fleiss1971measuring,
  title={Measuring nominal scale agreement among many raters.},
  author={Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={76},
  number={5},
  pages={378},
  year={1971},
  publisher={American Psychological Association}
}

@article{gelman2009,
author = {Andrew Gelman and David K. Park},
title = {Splitting a Predictor at the Upper Quarter or Third and the Lower Quarter or Third},
journal = {The American Statistician},
volume = {63},
number = {1},
pages = {1-8},
year  = {2009},
publisher = {Taylor & Francis}
}

@article{gorham_news_2006,
    title = {{News Media's Relationship With Stereotyping: The Linguistic Intergroup Bias in Response to Crime News}},
    volume = {56},
    issn = {1460-2466(Electronic),0021-9916(Print)},
        shorttitle = {{News Media's Relationship With Stereotyping}},
    abstract = {This paper examines the linguistic intergroup bias ({LIB}) in the context of people's interpretations of a race-related television news story. The {LIB} suggests that people use more abstract language to describe stereotype-congruent behaviors, particularly when that person is a member of an out-group. This study of 208 White adults manipulates the race of a suspect in a {TV} news crime story and examines how race influences the abstractness of the language viewers use to describe the suspect. The findings offer support for the {LIB} being induced by crime news and show that news media use is significantly related to the presence of the {LIB}. This suggests that stereotypical news coverage may subtly influence the interpretations people make about members of other social groups. ({PsycINFO} Database Record (c) 2018 {APA}, all rights reserved)},
    pages = {289--308},
    number = {2},
    journal = {Journal of Communication},
    author = {Gorham, Bradley W.},
    date = {2006},
    year = {2006},
    note = {Place: United Kingdom
Publisher: Blackwell Publishing},
    keywords = {Crime, Intergroup Dynamics, Linguistics, News Media, Racial and Ethnic Attitudes, Stereotyped Attitudes, Television}
}

@article{beltrama2020social,
  title={Social meaning in semantics and pragmatics},
  author={Beltrama, Andrea},
  journal={Language and Linguistics Compass},
  volume={14},
  number={9},
  pages={e12398},
  year={2020},
  publisher={Wiley Online Library}
}

@article{eckert2012three,
  title={Three waves of variation study: The emergence of meaning in the study of sociolinguistic variation},
  author={Eckert, Penelope},
  journal={Annual review of Anthropology},
  volume={41},
  pages={87--100},
  year={2012},
  publisher={Annual Reviews}
}

@inbook{Hall-Lew_Moore_Podesva_2021, place={Cambridge}, title={Social Meaning and Linguistic Variation: Theoretical Foundations}, booktitle={Social Meaning and Linguistic Variation: Theorizing the Third Wave}, publisher={Cambridge University Press}, author={Hall-Lew, Lauren and Moore, Emma and Podesva, Robert J.}, editor={Hall-Lew, Lauren and Moore, Emma and Podesva, Robert J.Editors}, year={2021}, pages={1–24}}
